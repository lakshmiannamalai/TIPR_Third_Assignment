{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fnil\fcharset0 Menlo-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red47\green180\blue29;
\red64\green11\blue217;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;\cssrgb\c20238\c73898\c14947;
\cssrgb\c32308\c18668\c88227;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 (venv)
\f1\b \cf4 e1-313-16222@clserv
\f0\b0 \cf2 :
\f1\b \cf5 ~/TIPR-Assignment-2/tipr-second-assignment/src
\f0\b0 \cf2 $ python main.py --train ../data/CIFAR-10 --test ../data --dataset CIFAR --configuration '[3 3]' --activation ReLu\
WARNING:tensorflow:From main.py:106: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\
Instructions for updating:\
\
Future major versions of TensorFlow will allow gradients to flow\
into the labels input on backprop by default.\
\
See `tf.nn.softmax_cross_entropy_with_logits_v2`.\
\
Training...\
2019-03-22 17:30:53.693102: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\
/storage2/home2/e1-313-16222/TIPR-Assignment-2/tipr-second-assignment/src/venv/local/lib/python2.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\
  warnings.warn(msg, DataConversionWarning)\
Loss:     1.6040 Validation Accuracy: 0.421000\
Loss:     1.2297 Validation Accuracy: 0.553000\
Loss:     1.0244 Validation Accuracy: 0.640000\
Loss:     0.9172 Validation Accuracy: 0.676000\
Loss:     0.7776 Validation Accuracy: 0.706000\
Loss:     0.6839 Validation Accuracy: 0.759000\
Loss:     0.7801 Validation Accuracy: 0.734000\
Loss:     0.5760 Validation Accuracy: 0.762000\
Loss:     0.3929 Validation Accuracy: 0.814000\
Loss:     0.3115 Validation Accuracy: 0.866000\
Loss:     0.2749 Validation Accuracy: 0.887000\
Loss:     0.2513 Validation Accuracy: 0.884000\
Loss:     0.1224 Validation Accuracy: 0.920000\
Loss:     0.3229 Validation Accuracy: 0.880000\
Loss:     0.1792 Validation Accuracy: 0.914000\
Loss:     0.2313 Validation Accuracy: 0.885000\
Loss:     0.0873 Validation Accuracy: 0.932000\
Loss:     0.0304 Validation Accuracy: 0.960000\
Loss:     0.0140 Validation Accuracy: 0.964000\
Loss:     0.0050 Validation Accuracy: 0.964000\
Loss:     0.0023 Validation Accuracy: 0.964000\
Loss:     0.0014 Validation Accuracy: 0.965000\
Loss:     0.0011 Validation Accuracy: 0.965000\
Loss:     0.0009 Validation Accuracy: 0.966000\
Loss:     0.0008 Validation Accuracy: 0.966000\
Loss:     0.0007 Validation Accuracy: 0.966000\
Loss:     0.0006 Validation Accuracy: 0.966000\
Loss:     0.0005 Validation Accuracy: 0.966000\
Loss:     0.0005 Validation Accuracy: 0.966000\
Loss:     0.0004 Validation Accuracy: 0.966000\
Loss:     0.0004 Validation Accuracy: 0.966000\
Loss:     0.0004 Validation Accuracy: 0.966000\
Loss:     0.0003 Validation Accuracy: 0.966000\
Loss:     0.0003 Validation Accuracy: 0.966000\
Loss:     0.0003 Validation Accuracy: 0.966000\
Loss:     0.0003 Validation Accuracy: 0.966000\
Loss:     0.0002 Validation Accuracy: 0.966000\
Loss:     0.0002 Validation Accuracy: 0.966000\
Loss:     0.0002 Validation Accuracy: 0.966000\
Loss:     0.0002 Validation Accuracy: 0.966000\
Loss:     0.0002 Validation Accuracy: 0.965000\
Loss:     0.0002 Validation Accuracy: 0.965000\
Loss:     0.0002 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Loss:     0.0001 Validation Accuracy: 0.965000\
Validation Accuracy :: 61.200000\
Validation Macro F1-Score :: 0.208759\
Validation Micro F1-Score :: 0.216205\
}